services:
  backend:
    build: 
      context: ./backend
      target: production
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - /app/venv
      - hf_cache:/root/.cache/huggingface
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - AZURE_CLIENT_ID=${AZURE_CLIENT_ID}
      - CHROMA_HOST=host.docker.internal
      - CHROMA_PORT=8001
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
    env_file:
      - .env
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    extra_hosts:
      - "host.docker.internal:host-gateway"

  frontend:
    build:
      context: ./frontend
      target: production
      args:
        VITE_API_URL: ${VITE_API_URL}
        VITE_AZURE_CLIENT_ID: ${VITE_AZURE_CLIENT_ID}
        VITE_AZURE_TENANT_ID: ${VITE_AZURE_TENANT_ID}
        VITE_AZURE_AUTHORITY: ${VITE_AZURE_AUTHORITY}
        VITE_BYPASS_AUTH: ${VITE_BYPASS_AUTH}
    ports:
      - "3001:80"
    depends_on:
      - backend

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./scripts/entrypoint.sh:/entrypoint.sh
    entrypoint: ["/bin/bash", "/entrypoint.sh"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  ollama_data:
  hf_cache:
