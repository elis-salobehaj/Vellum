RAG (Retrieval-Augmented Generation) is a technique that enhances the capabilities of Large Language Models (LLMs) by retrieving relevant information from an external knowledge base and using it to augment the prompt sent to the LLM. 

This allows the LLM to generate more accurate, up-to-date, and context-specific responses, reducing hallucinations and grounding the output in verifiable data.

Key Components of RAG:
1. Retrieval: Finding relevant documents from a vector database.
2. Augmentation: Combining the retrieved documents with the user's query.
3. Generation: The LLM generates the final answer based on the augmented context.
